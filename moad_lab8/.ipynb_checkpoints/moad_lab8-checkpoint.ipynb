{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практическое задание №8 Абдуллаева Вера группа 494а"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Необходимо выбрать любой (интересный на ваш взгляд) набор данных, подходящий для решения задачи классификации (https://scikit-learn.org/stable/datasets/toy_dataset.html#toy-datasets, например diabet, wine, breast_cancer; https://archive.ics.uci.edu/ml/index.php - выбор большой, kaggle.com)\n",
    "\n",
    "2) Выбрать не менее 3-х алгоритмов классификации данных, обосновать выбор, обучить модели. \n",
    "\n",
    "3) Оценить качество классификации. Подход к оценке и метрики оценки выбрать самостоятельно, обосновать выбор.\n",
    "\n",
    "4) Проинтерпретировать полученный результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать данные о клиентах страховой фирмы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем ниже кратко, что было предпринято для классификации и обучений моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему был испсользован классификатор RandomForestClassifier():\n",
    "\n",
    "Дерево решений — интуитивно понятная базовая единица алгоритма случайный лес. Мы можем рассматривать его как серию вопросов да/нет о входных данных. В конечном итоге вопросы приводят к предсказанию определённого класса (или величины в случае регрессии). Это интерпретируемая модель, так как решения принимаются так же, как и человеком: мы задаём вопросы о доступных данных до тех пор, пока не приходим к определённому решению (в идеальном мире).\n",
    "\n",
    "Базовая идея дерева решений заключается в формировании запросов, с которыми алгоритм обращается к данным. При использовании алгоритма CART вопросы (также называемые разделением узлов) определяются таким образом, чтобы ответы вели к уменьшению загрязнения Джини (Gini Impurity). Это означает, что дерево решений формирует узлы, содержащие большое количество образцов (из набора исходных данных), принадлежащих к одному классу. Алгоритм старается обнаружить параметры со сходными значениями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного о LogisticRegression или логистическая регрессия, которая является еще одним классификатором. Основным его свойством является\n",
    "тот факт, что он корректно оценивает вероятность принадлежности объекта к каждому из классов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV – это очень мощный инструмент для автоматического подбирания параметров для моделей машинного обучения. GridSearchCV находит наилучшие параметры, путем обычного перебора: он создает модель для каждой возможной комбинации параметров.\n",
    "Данный метод хоть и работает не очень быстро, но, при этом, экономит достаточно времени по сравнению с ручным перебором тех же параметров, чем дает явное преимущество в использовании при построении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier классификатор\n",
    "\n",
    "На интуитивном уровне суть метода проста: посмотри на соседей вокруг, какие из них преобладают, таковым ты и являешься. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных.\n",
    "В случае использования метода для классификации объект присваивается тому классу, который является наиболее распространённым среди k соседей данного элемента, классы которых уже известны.\n",
    "В случае использования метода для регрессии, объекту присваивается среднее значение по k ближайшим к нему объектам, значения которых уже известны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия | Тестовая точность измерений: 0.7952193917629895\n",
      "Случайный лес | Тестовая точность измерений: 0.7376725395578498\n",
      "Метод k ближайших соседей | Тестовая точность измерений: 0.7600998765570643\n",
      "['no']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Методы анализа и обработки данных\\\\moad_lab8\\\\insurance.csv')\n",
    "data.head()\n",
    "#Для создания модели нам необходимо вытащить целевой признак «smoker» в переменную y, а оставшиеся признаки в переменную X, предварительно\n",
    "# удалив неинтересующие нас при классификации данные:\n",
    "X = data.drop(['bmi','region','charges','smoker'], axis = 1)\n",
    "\n",
    "# Устанавливаем новые значения данных пола для работы с числовыми значениями\n",
    "X['sex'].where(~(X.sex =='male'), other=float(0), inplace=True)\n",
    "X['sex'].where(~(X.sex =='female'), other=float(1), inplace=True)\n",
    "\n",
    "y = data[['smoker']]\n",
    "#Разделяем наши данные для обучения\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size = 0.8, random_state = 1)\n",
    "\n",
    "#Определяем модели, которые будем обучать (способы классификации данных)\n",
    "logregr_cv = LogisticRegression(random_state = 0)\n",
    "randforest_cv = RandomForestClassifier()\n",
    "kn_cv = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "cv_dict = {0: 'Логистическая регрессия', \n",
    "           1: 'Случайный лес', \n",
    "           2: 'Метод k ближайших соседей'}\n",
    "\n",
    "\n",
    "cv_models = [logregr_cv, randforest_cv, kn_cv]\n",
    "           \n",
    "for i,model in enumerate(cv_models):\n",
    "    print(\"{} | Тестовая точность измерений: {}\".format(cv_dict[i], \n",
    "           cross_val_score(model, X, y.values.ravel(), cv = 10, scoring = 'accuracy').mean()))\n",
    "\n",
    "\n",
    "\n",
    "clsf = RandomForestClassifier()\n",
    "parametrs = { 'n_estimators': range (10, 51, 10),\n",
    "              'max_depth': range (1,13, 2),\n",
    "              'min_samples_leaf': range (1,8),\n",
    "              'min_samples_split': range (2,10,2) }\n",
    "grid = GridSearchCV(clsf, parametrs, cv=3) \n",
    "#CV – перекрёстная проверка (кросс-валидация, Cross-validation), метод, который показывает, что модель не переобучилась.\n",
    "# Если все результаты (в данном случае обучение проходит 3х моделей по 3м разным выборкам) хороши, значит модель не переобучена.\n",
    "best_model = grid.fit(X_train, y_train.values.ravel())\n",
    "Test = np.array([[40,0,0]]) \n",
    "# Возраст\\Пол\\Количество детей\n",
    "#Предсказываем курит ли человек\n",
    "prediction = best_model.predict(Test)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7215b31550dffcd2c6a7e2128f7e08765e5d2cd108d679b7c98db6c48c62c200"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
